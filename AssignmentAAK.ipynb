{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KXYNHTaL548r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hcBzx7C657s_"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Constants\n",
        "NUM_CLASSES = 10\n",
        "NUM_TRAIN_SAMPLES_PER_CLASS = 1000\n",
        "NUM_TOTAL_TRAIN_SAMPLES = NUM_CLASSES * NUM_TRAIN_SAMPLES_PER_CLASS\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cycqi4w6CgU",
        "outputId": "f2b3bbaa-e293-4f30-f51b-824a69b5d5a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # CIFAR-10 normalization\n",
        "])\n",
        "# Load CIFAR10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=train_transform)\n",
        "\n",
        "# Select a subset of training data\n",
        "indices = torch.arange(NUM_TOTAL_TRAIN_SAMPLES)\n",
        "subset_indices = torch.cat([indices[i:i+NUM_TRAIN_SAMPLES_PER_CLASS] for i in range(0, len(indices), NUM_TRAIN_SAMPLES_PER_CLASS)])\n",
        "train_dataset = torch.utils.data.Subset(train_dataset, subset_indices)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nVwNoL0y6iKL"
      },
      "outputs": [],
      "source": [
        "# Define ResNet20 model\n",
        "class ResNet20(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(ResNet20, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.layer1 = self._make_layer(16, 16, 3)\n",
        "    self.layer2 = self._make_layer(16, 32, 3, stride=2)\n",
        "    self.layer3 = self._make_layer(32, 64, 3, stride=2)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "  def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False))\n",
        "    layers.append(nn.BatchNorm2d(out_channels))\n",
        "    layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "    for _ in range(1, num_blocks):\n",
        "        layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-mCe19czvXX",
        "outputId": "4b058d11-8d50-4cdd-ba33-6ef724333b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 - Train Loss: 1.7627, Train Acc: 0.3486, Test Acc: 0.3945\n",
            "Epoch 2/100 - Train Loss: 1.4534, Train Acc: 0.4684, Test Acc: 0.4697\n",
            "Epoch 3/100 - Train Loss: 1.3175, Train Acc: 0.5207, Test Acc: 0.5150\n",
            "Epoch 4/100 - Train Loss: 1.2080, Train Acc: 0.5587, Test Acc: 0.4989\n",
            "Epoch 5/100 - Train Loss: 1.1143, Train Acc: 0.6054, Test Acc: 0.5313\n",
            "Epoch 6/100 - Train Loss: 1.0337, Train Acc: 0.6301, Test Acc: 0.5838\n",
            "Epoch 7/100 - Train Loss: 0.9471, Train Acc: 0.6669, Test Acc: 0.6012\n",
            "Epoch 8/100 - Train Loss: 0.8712, Train Acc: 0.6860, Test Acc: 0.6048\n",
            "Epoch 9/100 - Train Loss: 0.8066, Train Acc: 0.7110, Test Acc: 0.6145\n",
            "Epoch 10/100 - Train Loss: 0.7276, Train Acc: 0.7438, Test Acc: 0.6080\n",
            "Epoch 11/100 - Train Loss: 0.6687, Train Acc: 0.7645, Test Acc: 0.5801\n",
            "Epoch 12/100 - Train Loss: 0.5955, Train Acc: 0.7886, Test Acc: 0.6219\n",
            "Epoch 13/100 - Train Loss: 0.5340, Train Acc: 0.8116, Test Acc: 0.5650\n",
            "Epoch 14/100 - Train Loss: 0.4554, Train Acc: 0.8399, Test Acc: 0.6187\n",
            "Epoch 15/100 - Train Loss: 0.4116, Train Acc: 0.8588, Test Acc: 0.6129\n",
            "Epoch 16/100 - Train Loss: 0.3541, Train Acc: 0.8782, Test Acc: 0.6251\n",
            "Epoch 17/100 - Train Loss: 0.3323, Train Acc: 0.8886, Test Acc: 0.5984\n",
            "Epoch 18/100 - Train Loss: 0.2522, Train Acc: 0.9140, Test Acc: 0.6016\n",
            "Epoch 19/100 - Train Loss: 0.2053, Train Acc: 0.9341, Test Acc: 0.6123\n",
            "Epoch 20/100 - Train Loss: 0.2047, Train Acc: 0.9294, Test Acc: 0.6105\n",
            "Epoch 21/100 - Train Loss: 0.1786, Train Acc: 0.9411, Test Acc: 0.6008\n",
            "Epoch 22/100 - Train Loss: 0.1589, Train Acc: 0.9473, Test Acc: 0.6163\n",
            "Epoch 23/100 - Train Loss: 0.1530, Train Acc: 0.9491, Test Acc: 0.6087\n",
            "Epoch 24/100 - Train Loss: 0.1302, Train Acc: 0.9588, Test Acc: 0.6159\n",
            "Epoch 25/100 - Train Loss: 0.1154, Train Acc: 0.9622, Test Acc: 0.6144\n",
            "Epoch 26/100 - Train Loss: 0.1163, Train Acc: 0.9605, Test Acc: 0.6185\n",
            "Epoch 27/100 - Train Loss: 0.1294, Train Acc: 0.9578, Test Acc: 0.5984\n",
            "Epoch 28/100 - Train Loss: 0.1140, Train Acc: 0.9607, Test Acc: 0.5820\n",
            "Epoch 29/100 - Train Loss: 0.1192, Train Acc: 0.9620, Test Acc: 0.6189\n",
            "Epoch 30/100 - Train Loss: 0.1086, Train Acc: 0.9620, Test Acc: 0.6149\n",
            "Epoch 31/100 - Train Loss: 0.0803, Train Acc: 0.9722, Test Acc: 0.6102\n",
            "Epoch 32/100 - Train Loss: 0.0581, Train Acc: 0.9828, Test Acc: 0.6202\n",
            "Epoch 33/100 - Train Loss: 0.0704, Train Acc: 0.9762, Test Acc: 0.6156\n",
            "Epoch 34/100 - Train Loss: 0.0873, Train Acc: 0.9705, Test Acc: 0.5987\n",
            "Epoch 35/100 - Train Loss: 0.0707, Train Acc: 0.9787, Test Acc: 0.6053\n",
            "Epoch 36/100 - Train Loss: 0.0964, Train Acc: 0.9671, Test Acc: 0.6111\n",
            "Epoch 37/100 - Train Loss: 0.0903, Train Acc: 0.9696, Test Acc: 0.6078\n",
            "Epoch 38/100 - Train Loss: 0.0922, Train Acc: 0.9676, Test Acc: 0.6064\n",
            "Epoch 39/100 - Train Loss: 0.0852, Train Acc: 0.9716, Test Acc: 0.5973\n",
            "Epoch 40/100 - Train Loss: 0.0687, Train Acc: 0.9759, Test Acc: 0.6118\n",
            "Epoch 41/100 - Train Loss: 0.0530, Train Acc: 0.9828, Test Acc: 0.6089\n",
            "Epoch 42/100 - Train Loss: 0.0628, Train Acc: 0.9785, Test Acc: 0.6040\n",
            "Epoch 43/100 - Train Loss: 0.0860, Train Acc: 0.9711, Test Acc: 0.5991\n",
            "Epoch 44/100 - Train Loss: 0.0747, Train Acc: 0.9722, Test Acc: 0.6046\n",
            "Epoch 45/100 - Train Loss: 0.0633, Train Acc: 0.9766, Test Acc: 0.6005\n",
            "Epoch 46/100 - Train Loss: 0.0625, Train Acc: 0.9778, Test Acc: 0.6025\n",
            "Epoch 47/100 - Train Loss: 0.0975, Train Acc: 0.9677, Test Acc: 0.5969\n",
            "Epoch 48/100 - Train Loss: 0.0966, Train Acc: 0.9676, Test Acc: 0.5964\n",
            "Epoch 49/100 - Train Loss: 0.0473, Train Acc: 0.9846, Test Acc: 0.6200\n",
            "Epoch 50/100 - Train Loss: 0.0269, Train Acc: 0.9920, Test Acc: 0.6222\n",
            "Epoch 51/100 - Train Loss: 0.0272, Train Acc: 0.9918, Test Acc: 0.6210\n",
            "Epoch 52/100 - Train Loss: 0.0360, Train Acc: 0.9882, Test Acc: 0.6193\n",
            "Epoch 53/100 - Train Loss: 0.0662, Train Acc: 0.9773, Test Acc: 0.5989\n",
            "Epoch 54/100 - Train Loss: 0.0802, Train Acc: 0.9713, Test Acc: 0.6233\n",
            "Epoch 55/100 - Train Loss: 0.0671, Train Acc: 0.9793, Test Acc: 0.6160\n",
            "Epoch 56/100 - Train Loss: 0.0683, Train Acc: 0.9781, Test Acc: 0.6063\n",
            "Epoch 57/100 - Train Loss: 0.0914, Train Acc: 0.9682, Test Acc: 0.6196\n",
            "Epoch 58/100 - Train Loss: 0.0394, Train Acc: 0.9875, Test Acc: 0.6261\n",
            "Epoch 59/100 - Train Loss: 0.0367, Train Acc: 0.9884, Test Acc: 0.6208\n",
            "Epoch 60/100 - Train Loss: 0.0380, Train Acc: 0.9878, Test Acc: 0.6241\n",
            "Epoch 61/100 - Train Loss: 0.0511, Train Acc: 0.9834, Test Acc: 0.6123\n",
            "Epoch 62/100 - Train Loss: 0.0393, Train Acc: 0.9873, Test Acc: 0.6188\n",
            "Epoch 63/100 - Train Loss: 0.0383, Train Acc: 0.9870, Test Acc: 0.6063\n",
            "Epoch 64/100 - Train Loss: 0.0648, Train Acc: 0.9797, Test Acc: 0.6085\n",
            "Epoch 65/100 - Train Loss: 0.0818, Train Acc: 0.9727, Test Acc: 0.6119\n",
            "Epoch 66/100 - Train Loss: 0.0479, Train Acc: 0.9845, Test Acc: 0.6194\n",
            "Epoch 67/100 - Train Loss: 0.0253, Train Acc: 0.9908, Test Acc: 0.6223\n",
            "Epoch 68/100 - Train Loss: 0.0159, Train Acc: 0.9961, Test Acc: 0.6300\n",
            "Epoch 69/100 - Train Loss: 0.0512, Train Acc: 0.9839, Test Acc: 0.6070\n",
            "Epoch 70/100 - Train Loss: 0.0582, Train Acc: 0.9796, Test Acc: 0.6091\n",
            "Epoch 71/100 - Train Loss: 0.0479, Train Acc: 0.9828, Test Acc: 0.6230\n",
            "Epoch 72/100 - Train Loss: 0.0292, Train Acc: 0.9902, Test Acc: 0.6220\n",
            "Epoch 73/100 - Train Loss: 0.0256, Train Acc: 0.9915, Test Acc: 0.6211\n",
            "Epoch 74/100 - Train Loss: 0.0258, Train Acc: 0.9927, Test Acc: 0.6139\n",
            "Epoch 75/100 - Train Loss: 0.0660, Train Acc: 0.9783, Test Acc: 0.6086\n",
            "Epoch 76/100 - Train Loss: 0.0644, Train Acc: 0.9792, Test Acc: 0.6187\n",
            "Epoch 77/100 - Train Loss: 0.0630, Train Acc: 0.9798, Test Acc: 0.6144\n",
            "Epoch 78/100 - Train Loss: 0.0373, Train Acc: 0.9883, Test Acc: 0.6265\n",
            "Epoch 79/100 - Train Loss: 0.0427, Train Acc: 0.9866, Test Acc: 0.6255\n",
            "Epoch 80/100 - Train Loss: 0.0414, Train Acc: 0.9857, Test Acc: 0.6192\n",
            "Epoch 81/100 - Train Loss: 0.0405, Train Acc: 0.9866, Test Acc: 0.6059\n",
            "Epoch 82/100 - Train Loss: 0.0491, Train Acc: 0.9832, Test Acc: 0.6120\n",
            "Epoch 83/100 - Train Loss: 0.0232, Train Acc: 0.9919, Test Acc: 0.6209\n",
            "Epoch 84/100 - Train Loss: 0.0146, Train Acc: 0.9962, Test Acc: 0.6211\n",
            "Epoch 85/100 - Train Loss: 0.0151, Train Acc: 0.9954, Test Acc: 0.6208\n",
            "Epoch 86/100 - Train Loss: 0.0171, Train Acc: 0.9949, Test Acc: 0.6102\n",
            "Epoch 87/100 - Train Loss: 0.0752, Train Acc: 0.9746, Test Acc: 0.6010\n",
            "Epoch 88/100 - Train Loss: 0.0719, Train Acc: 0.9760, Test Acc: 0.6035\n",
            "Epoch 89/100 - Train Loss: 0.0569, Train Acc: 0.9813, Test Acc: 0.6219\n",
            "Epoch 90/100 - Train Loss: 0.0398, Train Acc: 0.9864, Test Acc: 0.6033\n",
            "Epoch 91/100 - Train Loss: 0.0234, Train Acc: 0.9927, Test Acc: 0.6206\n",
            "Epoch 92/100 - Train Loss: 0.0305, Train Acc: 0.9892, Test Acc: 0.6169\n",
            "Epoch 93/100 - Train Loss: 0.0274, Train Acc: 0.9916, Test Acc: 0.6178\n",
            "Epoch 94/100 - Train Loss: 0.0146, Train Acc: 0.9959, Test Acc: 0.6221\n",
            "Epoch 95/100 - Train Loss: 0.0150, Train Acc: 0.9959, Test Acc: 0.6249\n",
            "Epoch 96/100 - Train Loss: 0.0133, Train Acc: 0.9952, Test Acc: 0.6050\n",
            "Epoch 97/100 - Train Loss: 0.0524, Train Acc: 0.9833, Test Acc: 0.5982\n",
            "Epoch 98/100 - Train Loss: 0.0664, Train Acc: 0.9770, Test Acc: 0.6010\n",
            "Epoch 99/100 - Train Loss: 0.0673, Train Acc: 0.9774, Test Acc: 0.5995\n",
            "Epoch 100/100 - Train Loss: 0.0296, Train Acc: 0.9908, Test Acc: 0.6266\n"
          ]
        }
      ],
      "source": [
        " model = ResNet20(num_classes=NUM_CLASSES)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(outputs, labels):\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  correct = (predicted == labels).sum().item()\n",
        "  total = labels.size(0)\n",
        "  accuracy = correct / total\n",
        "  return accuracy\n",
        "\n",
        "# Training loop\n",
        "train_loss_history = []\n",
        "train_acc_history = []\n",
        "test_acc_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()  # Set model to training mode\n",
        "  train_loss = 0.0\n",
        "  train_correct = 0\n",
        "  train_total = 0\n",
        "\n",
        "  # Iterate over training dataset\n",
        "  for inputs, labels in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "      train_total += labels.size(0)\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "  train_accuracy = train_correct / train_total\n",
        "\n",
        "  # Evaluate on the test dataset\n",
        "  model.eval()  # Set model to evaluation mode\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in test_loader:\n",
        "          outputs = model(inputs)\n",
        "          test_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "          test_total += labels.size(0)\n",
        "\n",
        "  test_accuracy = test_correct / test_total\n",
        "\n",
        "  # Record history\n",
        "  train_loss_history.append(train_loss)\n",
        "  train_acc_history.append(train_accuracy)\n",
        "  test_acc_history.append(test_accuracy)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{EPOCHS} - \"\n",
        "    f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
        "    f\"Test Acc: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set model to evaluation mode\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        test_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        test_total += labels.size(0)\n",
        "\n",
        "test_accuracy = test_correct / test_total\n",
        "\n"
      ],
      "metadata": {
        "id": "vS59H7cNUb3R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final Test Accuracy:\",test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlufMWdRBaLC",
        "outputId": "46d3bf85-a462-4ac0-ec9a-1f306b9c7b10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.6266\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}